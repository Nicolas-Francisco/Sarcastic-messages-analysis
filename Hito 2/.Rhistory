library(tidyverse)
sarcasmo <- read_csv("../../train-balanced-sarcasm.csv")
library(tidyverse)
sarcasmo <- read_csv("../../train-balanced-sarcasm.csv")
head(sarcasmo)
# Suma de valores NA en todas las columnas del dataset
sum(is.na(sarcasmo$comment))
sum(is.na(sarcasmo$author))
sum(is.na(sarcasmo$subreddit))
sum(is.na(sarcasmo$score))
sum(is.na(sarcasmo$ups))
sum(is.na(sarcasmo$downs))
sum(is.na(sarcasmo$date))
sum(is.na(sarcasmo$created_utc))
sum(is.na(sarcasmo$parent_comment))
# Mostrar existencia de filas con valores NA (notar que no son las que tienen como mentario el string '0', si no las que tienen datos NA)
sarcasmo[sarcasmo$comment == 0,]
sarcasmo=sarcasmo[is.na(sarcasmo$author)==FALSE,]
head(sarcasmo)
dim(sarcasmo)
summary(sarcasmo)
library(tm)
docs <- VectorSource(sarcasmo[,c("comment")])
docs <- VCorpus(docs)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, content_transformer(gsub), pattern = "/", replacement = "")
docs <- tm_map(docs, content_transformer(gsub), pattern = '[[:digit:]]+', replacement = "")  # elimina cualquier digito
docs <- tm_map(docs, content_transformer(iconv), from="UTF-8",to="ASCII//TRANSLIT")
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
docs <- tm_map(docs, content_transformer(removeSpecialChars))
dtm <- DocumentTermMatrix(docs)
inspect(dtm)
dtm.matrix <- as.matrix(dtm)
freq <- colSums(dtm.matrix)
word_freq <- data.frame(word = names(freq), freq = freq, row.names = NULL)
word_freq <- word_freq[order(-word_freq$freq),]
library(ggplot2)
ggplot(word_freq[1:20,], aes(x = reorder(word, freq), y = freq)) +
geom_bar(stat = "identity") +
coord_flip()+
ggtitle(label = "Top-20 palabras presentes en comentarios sarcasticos") + xlab("Palabras") + ylab("Frecuencia")
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm.sw <- DocumentTermMatrix(docs)
dtm.sw.matrix <- as.matrix(dtm.sw)
freq.sw <- colSums(dtm.sw.matrix)
word_freq.sw <- data.frame(word = names(freq.sw), freq = freq.sw, row.names = NULL)
word_freq.sw <- word_freq.sw[order(-word_freq.sw$freq),]
ggplot(word_freq.sw[1:20,], aes(x = reorder(word, freq), y = freq)) +
geom_bar(stat = "identity") +
coord_flip()+
ggtitle(label = "Top-20 palabras presentes en comentarios sarcasticos sin considerar stopwords")  + xlab("Palabras") + ylab("Frecuencia")
docs <- VectorSource(sarcasmo[,c("parent_comment")])
docs <- VCorpus(docs)
inspect(docs)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, content_transformer(gsub), pattern = "/", replacement = "")
docs <- tm_map(docs, content_transformer(gsub), pattern = '[[:digit:]]+', replacement = "")  # elimina cualquier digito
docs <- tm_map(docs, content_transformer(iconv), from="UTF-8",to="ASCII//TRANSLIT")
removeSpecialChars <- function(x) gsub("[^a-zA-Z0-9 ]","",x)
docs <- tm_map(docs, content_transformer(removeSpecialChars))
dtm <- DocumentTermMatrix(docs)
inspect(dtm)
dtm.matrix <- as.matrix(dtm)
freq <- colSums(dtm.matrix)
word_freq <- data.frame(word = names(freq), freq = freq, row.names = NULL)
word_freq <- word_freq[order(-word_freq$freq),]
ggplot(word_freq[1:20,], aes(x = reorder(word, freq), y = freq)) +
geom_bar(stat = "identity") +
coord_flip()+
ggtitle(label = "Top-20 palabras presentes en comentarios padre") + xlab("Palabras") + ylab("Frecuencia")
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm.sw <- DocumentTermMatrix(docs)
dtm.sw.matrix <- as.matrix(dtm.sw)
freq.sw <- colSums(dtm.sw.matrix)
word_freq.sw <- data.frame(word = names(freq.sw), freq = freq.sw, row.names = NULL)
word_freq.sw <- word_freq.sw[order(-word_freq.sw$freq),]
ggplot(word_freq.sw[1:20,], aes(x = reorder(word, freq), y = freq)) +
geom_bar(stat = "identity") +
coord_flip()+
ggtitle(label = "Top-20 palabras presentes en comentarios padre sin considerar stopwords") + xlab("Palabras") + ylab("Frecuencia")
# Obtener frecuencia de los años de los comentarios sarcasticos
anhos=substr(sarcasmo$date,1,4)
anhos=table(anhos)
anhos=data.frame(anhos)
barplot(anhos$Freq, names.arg = anhos$anhos, main="Comentarios sarcasticos a través del tiempo", xlab = "Años", ylab = "Frecuencia")
docs <- VectorSource(sarcasmo[,c("subreddit")])
docs <- VCorpus(docs)
inspect(docs)
dtm <- DocumentTermMatrix(docs)
inspect(dtm)
dtm.matrix <- as.matrix(dtm)
freq <- colSums(dtm.matrix)
subreddit_freq <- data.frame(subreddit = names(freq), freq = freq, row.names = NULL)
subreddit_freq <- subreddit_freq[order(-subreddit_freq$freq),]
head(subreddit_freq)
ggplot(subreddit_freq[1:20,], aes(x = reorder(subreddit, freq), y = freq)) +
geom_bar(stat = "identity") +
coord_flip()+
ggtitle(label = "Top-20 subreddits presentes en el dataset")  + xlab("Subreddit") + ylab("Frecuencia")
porTopico <- sarcasmo %>%
group_by(subreddit) %>% # Agrupar los subreddit
summarise(total = sum(score)) %>% # ordenados de menor a mayor por el score de sus comentarios sarcasticos
arrange(-total) # Ordenarlos de mayor a menor
porTopico = porTopico[0:20,] # 20 subreddits con más score en sus comentarios sarcasticos
head(porTopico)
ggplot(data = porTopico, aes(x = reorder(subreddit, total), y=total)) + geom_bar(stat = "identity")+coord_flip()+
ggtitle(label = "Top-20 subreddits con el mejor score")  + xlab("Subreddit") + ylab("Score")
Length_comment=str_length(sarcasmo$comment)
hist(Length_comment,xlim=c(0,1000), breaks = 1000, main = "Cantidad de caracteres por comentario sarcastico",
xlab = "Cantidad de caracteres", ylab = "Frecuencia" )
# Resumen de estadísticas del largo de los comentarios sarcasticos
summary(Length_comment)
sarcasmo[str_length(sarcasmo$comment) == 10000,]
Lenght_parent=str_length(sarcasmo$parent_comment)
hist(Lenght_parent,xlim=c(0,1000), breaks = 1000, main = "Cantidad de caracteres por comentario padre",
xlab = "Cantidad de caracteres", ylab = "Frecuencia" )
# Resumen de estadísticas del largo de los comentarios padre
summary(Lenght_parent)
